{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook\n",
    "Our *Test score* for IMDB reviews data: **0.89736** \n",
    "\n",
    "*Test score* for 20 Newsgroup: **0.699196176314392**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from spellchecker import SpellChecker # pip install pyspellchecker\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: 20 newsgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', remove=(['headers', 'footers', 'quotes']), shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', remove=(['headers', 'footers', 'quotes']), shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data: IMDB reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "# Change the path to your dir\n",
    "imdb_train = load_files(container_path=\"......\\\\551A1\\\\aclImdb_v1\\\\aclImdb\\\\train\", categories=[\"pos\", \"neg\"], description=\"IMAD review, Train\")\n",
    "imdb_test= load_files(container_path=\"......\\\\551A1\\\\aclImdb_v1\\\\aclImdb\\\\test\",categories=[\"pos\", \"neg\"], description=\"IMAD review, Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "For **20 newsgroup** data, preprocessing procedure is:\n",
    "1. Remove all non-words\n",
    "2. Transform the review in lower case\n",
    "3. Remove all stop words\n",
    "4. Perform stemming/lemmating\n",
    "5. Check and correct spelling\n",
    "\n",
    "For **IMDB reviews** data, preprocessing procedure is:\n",
    "1. Remove all non-words\n",
    "2. Transform the review in lower case\n",
    "3. Remove all stop words\n",
    "4. Perform stemming/lemmating\n",
    "\n",
    "The reason why IMDB reviews data preprocessing procedure is lack of check and correct spelling is that it takes more than 10 hours to train with 12 cores by having it in the procedure, which is not applicable for the real-world scenario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spellings(word):\n",
    "    \"\"\"\n",
    "    Check misspelling words and convert it to its correct format\n",
    "    \"\"\"\n",
    "    spell = SpellChecker()\n",
    "    if spell.unknown(word) == set():\n",
    "        return word\n",
    "    else:\n",
    "        return spell.correction(word)\n",
    "\n",
    "def clean(texts, algo):\n",
    "    \"\"\"\n",
    "    Receives a raw review and clean it using the following steps:\n",
    "    1. Remove all non-words\n",
    "    2. Transform the review in lower case\n",
    "    3. Remove all stop words\n",
    "    4. Perform stemming\n",
    "\n",
    "    Args:\n",
    "        review: the review that iwill be cleaned\n",
    "    Returns:\n",
    "        a clean review using the mentioned steps above.\n",
    "    Cite Github\n",
    "    \"\"\"\n",
    "    texts = re.sub(\"[^A-Za-z]\", \" \", texts)\n",
    "    texts = texts.lower()\n",
    "    texts = word_tokenize(texts)\n",
    "    stopword = set(stopwords.words(\"english\"))\n",
    "    if algo == \"stemmer\":\n",
    "        wordAlgo = PorterStemmer()\n",
    "        texts = [(wordAlgo.stem(word)) for word in texts if word not in stopword]\n",
    "    else:\n",
    "        wordAlgo = WordNetLemmatizer()\n",
    "        texts = [(wordAlgo.lemmatize(word)) for word in texts if word not in stopword]\n",
    "    texts = \" \".join(texts)\n",
    "    return texts\n",
    "\n",
    "\n",
    "def check_count(data):\n",
    "    \"\"\"\n",
    "    Check for each words counts for removal\n",
    "    \"\"\"\n",
    "    cnt = Counter()\n",
    "    for text in data:\n",
    "        for word in text.split():\n",
    "            cnt[word] += 1\n",
    "\n",
    "    return cnt.most_common()\n",
    "\n",
    "\n",
    "def remove_freqwords(text, num_removal):\n",
    "    \"\"\"\n",
    "    Remove the most frequent words, such as \"I\", \"that\", which has a limited\n",
    "    importance to the model\n",
    "    \"\"\"\n",
    "    counts = check_count(text)\n",
    "    FREQWORDS = set([w for (w, wc) in counts[0:num_removal]])\n",
    "    return \" \".join([word for word in str(text).split() if word not in FREQWORDS])\n",
    "\n",
    "def remove_rarewords(text, num_removal):\n",
    "    \"\"\"\n",
    "    Remove the least frequent words, such as \"hmmmmm\", \"yoooooo\", which has a limited\n",
    "    importance to the model\n",
    "    \"\"\"\n",
    "    counts = check_count(text)\n",
    "    RAREWORDS = set([w for (w, wc) in counts[:-num_removal-1:-1] if wc <= 5])\n",
    "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing IMDB reviews data\n",
    "\n",
    "This strictly follows that procedure mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "#Preprocessing data\n",
    "reviews_data = pd.DataFrame(imdb_train.data, columns = [\"review\"])\n",
    "reviews_train = Parallel(n_jobs=-1)(delayed(clean)(str(reviews_data.review[i]), \"lemma\") for i in range(0, len(reviews_data)))\n",
    "reviews_data = pd.DataFrame(imdb_test.data, columns = [\"review\"])\n",
    "reviews_test = Parallel(n_jobs=-1)(delayed(clean)(str(reviews_data.review[i]), \"lemma\") for i in range(0, len(reviews_data)))\n",
    "#Remove freq words, such as 'I', 'that'\n",
    "reviews_train = [remove_freqwords(text,5) for text in reviews_train]\n",
    "#Remove rare words, such as  hmmmmmmmmm, yaaaaaaaap\n",
    "reviews_train = [remove_rarewords(text,20000) for text in reviews_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 20 Newsgroups data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data = pd.DataFrame(twenty_train.data, columns = [\"review\"])\n",
    "# Choose lemma for better model performance\n",
    "# Stemmer may cause the loss of ~5% accuracy\n",
    "news_train = [clean(str(news_data.review[i]), \"lemma\") for i in range(0, len(reviews_data))]\n",
    "news_data = pd.DataFrame(twenty_test.data, columns = [\"review\"])\n",
    "news_test = [clean(str(news_data.review[i]), \"lemma\") for i in range(0, len(reviews_data))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "\n",
    "Instead of assigning each paramters for different parameters, we would like to build a models() function to automatically call the parameters and pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(mod):\n",
    "    '''\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    mod: str\n",
    "    model name: rf, ada, svm, dt, logistic, knn, nb\n",
    "    '''\n",
    "    if mod == \"rf\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('rf', RandomForestClassifier())])\n",
    "        parameters = {\n",
    "        'rf__n_estimators': [1000,5000],\n",
    "        'rf__max_features':[10, 50],\n",
    "        'rf__max_depth':[300,1000],\n",
    "        'rf__n_jobs' : [5]\n",
    "        }\n",
    "    elif mod == \"ada\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('ada', AdaBoostClassifier())])\n",
    "        parameters = {\n",
    "        'ada__n_estimators':[100,500,1000],\n",
    "        'ada__learning_rate':[1.,0.1],\n",
    "        'ada__base_estimator': [DecisionTreeClassifier()]}\n",
    "    elif mod == \"svm\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('svm', LinearSVC())])\n",
    "        parameters = {\n",
    "        'svm__penalty': [\"l1\", \"l2\"],\n",
    "        'svm__loss':[\"hinge\",\"squared_hinge\"],\n",
    "        'svm__multi_class':[\"ovr\",\"crammer_singer\"],\n",
    "        'svm__C': [0.15, 0.77, 1, 10],\n",
    "        'svm__max_iter':[5000,10000]\n",
    "        }\n",
    "    elif mod == \"dt\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('dt', DecisionTreeClassifier())])\n",
    "        parameters = {\n",
    "        'dt__max_features':[\"auto\", \"log2\"],\n",
    "        'dt__splitter': [\"best\",\"random\"]\n",
    "        }\n",
    "    elif mod == \"logistic\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('logistic', LogisticRegression())])\n",
    "        parameters = {\n",
    "        'logistic__penalty':[\"l2\"],\n",
    "        'logistic__solver':[\"newton-cg\",\"lbfgs\",\"sag\"],\n",
    "        'logistic__C': [0.1, 0.5, 0.7, 1],\n",
    "        'logistic__n_jobs':[-1],\n",
    "        'logistic__max_iter':[100,500]\n",
    "        }\n",
    "    elif mod == \"knn\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('knn', KNeighborsClassifier())])\n",
    "        parameters = {\n",
    "        'knn__n_neighbors':[5,10,15],\n",
    "        'knn__weights':[\"uniform\",\"distance\"],\n",
    "        'knn__algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'knn__n_jobs':[-1]\n",
    "        }\n",
    "    elif mod == \"nb\":\n",
    "        model = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('nb', MultinomialNB())])\n",
    "        parameters = {\n",
    "        'nb__alpha':[1.0,0.0],\n",
    "        'nb__fit_prior':[True, False]\n",
    "        }\n",
    "    return (model, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training\n",
    "\n",
    "The training function is designed for every models in our list and it will print necessary information that we used to validate the model, such as best parameters and best validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train, target, model, cv, parameters = None):\n",
    "    '''\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    train: input data\n",
    "\n",
    "    target: input target\n",
    "\n",
    "    model: predefined model class\n",
    "\n",
    "    cv: int\n",
    "    number of splits for CV\n",
    "\n",
    "    GridSearch paramters: dict\n",
    "    '''\n",
    "    print(\"Model: {}\".format(model))\n",
    "\n",
    "    if parameters is None:\n",
    "        model.fit(train, target)\n",
    "        score = cross_validate(model, train, target, cv = cv)\n",
    "        print(\"Cross Validation Scores: {}\".format(score))\n",
    "        print(\"Training accuracy: {}\".format(model.score(train, target)))\n",
    "    else:\n",
    "        print(\"{} starts\".format(model))\n",
    "        model = GridSearchCV(model, parameters, cv=cv, n_jobs=11, verbose = 3)\n",
    "        model.fit(train, target)\n",
    "        print(\"Best params: {}\".format(model.best_params_))\n",
    "        print(\"Validation results: {}\".format(model.cv_results_))\n",
    "    return model, model.best_params, model.cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "We take LinearSVC and IMDB data as our example to illustrate the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model, paramters = models(\"svm\")\n",
    "# train() parameters setup\n",
    "train = reviews_train\n",
    "target = imdb_train.target\n",
    "model = model\n",
    "cv = 5 \n",
    "parameters = paramters\n",
    "start = time.time()\n",
    "svm, best_params, cv_results = train(train, target, model, cv, parameters = paramters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating model\n",
    "\n",
    "After training the model, we would like to evaluate the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test, target):\n",
    "    print(\"Test accuracy: {}\".format(np.mean(model.predict(test) == target)))\n",
    "    print(\"Classification report: {}\".format(classification_report(target, model.predict(test))))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(svm, reviews_test, imdb_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Hyperparameters for Each Model\n",
    "\n",
    "Training process is done, we would like to emphasize the best performed model for each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results\n",
    "\n",
    "For now, after cleaning the words and grid search the hypterparameters, regarding both IMDB and 20 Newsgroup data LinearSVC() reaches the highest test accuracy across all models\n",
    "\n",
    "\n",
    "* **IMDB** Best SVM parameters: {'svm__C': 0.1, 'svm__loss': 'hinge', 'svm__max_iter': 1000, 'svm__multi_class': 'ovr', 'svm__penalty': 'l2'}\n",
    "\n",
    "    *Test score*: 0.8639\n",
    "\n",
    "\n",
    "\n",
    "* **20 Newsgroup** Best SVM parameters: {'svm__C': 0.1, 'svm__loss': 'hinge', 'svm__max_iter': 2000, 'svm__multi_class': 'ovr', 'svm__penalty': 'l2'}\n",
    "\n",
    "    *Test score*: 0.67950"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model across all Best Models\n",
    "\n",
    "We select the models that fit the two dataset best from more than hundreds models. Then we apply different CountVectorizer() parameters to seek better performance. After another grid search,for both IMDB and 20 Newsgroup data, LinearSVC() reaches the highest test accuracy across all models, \n",
    "\n",
    "* **IMDB** Best SVM parameters: {'svm__C': 10, 'svm__loss': 'hinge', 'svm__max_iter': 5000, 'svm__multi_class': 'ovr', 'svm__penalty': 'l2', 'vect__analyzer': 'word', 'vect__binary': True, 'vect__ngram_range': (1, 2), 'vect__strip_accents': 'unicode'}\n",
    "\n",
    "    *Test score*: **0.89736** \n",
    "\n",
    "\n",
    "\n",
    "* **20 Newsgroup** Best SVM parameters: {'svm__C': 0.77, 'svm__loss': 'hinge', 'svm__max_iter': 5000, 'svm__multi_class': 'ovr', 'svm__penalty': 'l2', 'vect__analyzer': 'word', 'vect__binary': True, 'vect__ngram_range': (1, 1), 'vect__strip_accents': None}\n",
    "\n",
    "    *Test score*: **0.699196176314392**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign parameters to Grid Search \n",
    "parameters = {'vect__ngram_range': [(1,1), (1,2), (2,2)],\n",
    "              'vect__binary': [True],\n",
    "              'vect__analyzer':['word'],\n",
    "              'vect__strip_accents': ['unicode', None],\n",
    "              'svm__C': [0.15, 0.77, 1, 10],\n",
    "             'svm__loss': ['hinge'],\n",
    "             'svm__max_iter': [5000],\n",
    "             'svm__multi_class': ['ovr'],\n",
    "             'svm__penalty': ['l2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "By far, we used the pipeline of NLP preprocesing techniques, machine learning classification model, grid search the best hyperparameters, and model selection to help our tuning and fitting. Both datasets are having the highest accuracy on SVM model, though their parameters are slightly different. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
